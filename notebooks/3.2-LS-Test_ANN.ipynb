{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\luiss\\\\Python Process Control\\\\Github Folder\\\\HW3\\\\meters\\\\source'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#os.chdir(\"..\\meters\\source\")\n",
    "os.chdir(\"..\\meters\\source\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\luiss\\\\Python Process Control\\\\Github Folder\\\\HW3\\\\meters'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import tree\n",
    "from data_preprocess import DataPreprocessing\n",
    "from model_builder import ModelBuilder\n",
    "from model_builder2 import ModelBuilder2\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3          4          5         6   \\\n",
      "0  0.841499  1.009367  0.993816  8.469805  10.278727  10.037759  8.501365   \n",
      "1  0.842250  1.006584  0.996605  7.531891   9.139924   8.951618  7.612213   \n",
      "2  0.840723  1.011647  0.998152  6.641699   7.975464   7.857692  6.593117   \n",
      "3  0.841119  1.017807  0.996812  5.687524   6.824334   6.689885  5.615428   \n",
      "4  0.840358  1.016534  0.996221  5.660385   6.829560   6.675628  5.623977   \n",
      "\n",
      "         7          8          9   ...         27         28         29  \\\n",
      "0  8.581726  10.247763  10.058822  ...  32.451173  34.568685  33.082683   \n",
      "1  7.623325   9.106345   8.945142  ...  32.428385  34.441732  33.081055   \n",
      "2  6.681572   7.964596   7.814698  ...  32.428385  34.275715  33.113605   \n",
      "3  5.763315   6.801051   6.686639  ...  32.485350  34.080403  33.170573   \n",
      "4  5.736818   6.813453   6.672377  ...  32.503255  34.122720  33.164062   \n",
      "\n",
      "          30         31         32         33         34         35  36  \n",
      "0  36.722005  36.969403  36.075847  36.051432  35.174155  32.729490   1  \n",
      "1  36.687825  36.933595  36.054688  35.979818  34.847005  32.731122   1  \n",
      "2  36.661785  36.873370  36.002605  35.963542  34.689128  32.771810   1  \n",
      "3  36.673177  36.811525  35.974935  35.955403  34.500328  32.849935   1  \n",
      "4  36.673177  36.826173  35.996095  35.968425  34.474283  32.853190   1  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocessing()\n",
    "\n",
    "data = preprocessor.load_data('data/Meter_A.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation, test = train_test_split(data, test_size = 0.2, random_state=12)\n",
    "\n",
    "train, validation = train_test_split(train_validation, test_size = 0.2, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(train[:, :-1])\n",
    "\n",
    "train_scaled = scaler.transform(train[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder2(DataPreprocessing):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModelBuilder2, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def ANN(self, X_train, X_test, y_train, y_test):\n",
    "        #Create ANN model\n",
    "        ANN_classifier2 = MLPClassifier()\n",
    "\n",
    "        #Train the model\n",
    "        ANN_classifier2.fit(X_train, y_train)\n",
    "\n",
    "        #Test the model\n",
    "        ANN_predicted2 = ANN_classifier2.predict(X_test)\n",
    "\n",
    "        error2 = 0\n",
    "        for i in range(len(y_test)):\n",
    "            error2 += np.sum(ANN_predicted2 != y_test)\n",
    "\n",
    "        total_accuracy2 = 1 - error2 / len(y_test)\n",
    "\n",
    "        #get performance\n",
    "        self.accuracy2 = accuracy_score(y_test, ANN_predicted2)\n",
    "\n",
    "        return ANN_classifier2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_builder2 = ModelBuilder2()\n",
    "\n",
    "dt_model2 = model_builder2.ANN(X_train=train[:, :-1], X_test=validation[:, :-1], y_train=train[:, -1], y_test = validation[:, -1])\n",
    "\n",
    "model_builder2.accuracy2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "627f0b05160b357a8475dba8e8f8e926f8a32a16d88e906205d58b7bdb2eabb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
